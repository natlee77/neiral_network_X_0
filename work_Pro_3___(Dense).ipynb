{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_qXycKuUA51"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUMmCXubUHEb"
      },
      "source": [
        "write a neural network that can become an integral part of the tic-tac-toe bot system. Using the prepared image database, create and train a neural network that recognizes two categories of images: tic and tac toe. Achieve over 95% recognition accuracy (accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "LvOL2h3EdC9y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras import utils \n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        "from PIL import Image \n",
        "%matplotlib inline \n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lJSH41rM12IE",
        "outputId": "5b228d77-11e6-4aa8-c87b-b14d991d8882"
      },
      "outputs": [],
      "source": [
        "# dataset\n",
        "#import gdown\n",
        "#gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l3/hw_pro.zip', None, quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HAhCsCJ1_hJ"
      },
      "outputs": [],
      "source": [
        "#  !unzip -q hw_pro.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhHbCet01zmG",
        "outputId": "cfa64aa9-5581-4650-b4c3-498c2c0bc6c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер массива x_train_base (102, 20, 20, 1)\n",
            "Размер массива y_train_base (102,)\n"
          ]
        }
      ],
      "source": [
        "# Путь к директории с базой\n",
        "base_dir = 'hw_pro'\n",
        "# Создание пустого списка для загрузки изображений обучающей выборки\n",
        "x_train = []\n",
        "# Создание списка для меток классов\n",
        "y_train = []\n",
        "# Задание высоты и ширины загружаемых изображений\n",
        "img_height = 20\n",
        "img_width = 20\n",
        "# Перебор папок в директории базы\n",
        "for patch in os.listdir(base_dir):\n",
        "    # Перебор файлов в папках\n",
        "    for img in os.listdir(base_dir + '/' + patch):\n",
        "        # Добавление в список изображений текущей картинки\n",
        "        x_train.append(image.img_to_array(image.load_img(base_dir + '/' + patch + '/' + img,\n",
        "                                                         target_size=(img_height, img_width),\n",
        "                                                         color_mode='grayscale')))\n",
        "        # Добавление в массив меток, соответствующих классам\n",
        "        if patch == '0':\n",
        "            y_train.append(0)\n",
        "        else:\n",
        "            y_train.append(1)\n",
        "# Преобразование в numpy-массив загруженных изображений и меток классов\n",
        "x_train_base= np.array(x_train)          # вход\n",
        "y_train_base = np.array(y_train)          # Вывод  \n",
        "# Вывод размерностей\n",
        "print('Размер массива x_train_base', x_train_base.shape)\n",
        "print('Размер массива y_train_base', y_train_base.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq6TSZP_HhIZ"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "RPFRDJJBJ1uw"
      },
      "outputs": [],
      "source": [
        "#Split the data to 70% training and 30% testing\n",
        "x_train_base , x_test_base, y_train_base, y_test_base = train_test_split(x_train_base, y_train_base, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8d-hR8Wo-Zx",
        "outputId": "8c77bb87-6146-4803-de4e-0a2a8713a6ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(31, 20, 20, 1)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test_base.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TwOtEYFpEt9",
        "outputId": "fb601704-03cd-4c26-a762-e5d1626dd4d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(31,)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_base.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgXoEh_W_Hfd",
        "outputId": "a5a98b42-828d-45fd-e6b8-8aa433d05aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер массива x_train_v (71, 400)\n",
            "Размер массива x_test_v (31, 400)\n"
          ]
        }
      ],
      "source": [
        "x_train_v = x_train_base.reshape(x_train_base.shape[0], -1)   #transform the image into a simpler form - into a one-dimensional sequence of numbers (vector).\n",
        "x_test_v= x_test_base.reshape(x_test_base.shape[0], -1)   \n",
        "print('Размер массива x_train_v', x_train_v.shape)\n",
        "print('Размер массива x_test_v', x_test_v.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3SF2mKcCnO3",
        "outputId": "71472cbd-9a26-4a10-f807-a8092dfa7753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(71, 400) (31, 400)\n"
          ]
        }
      ],
      "source": [
        "# Normalization of input pictures\n",
        "# Convert x_train to type float32 (floating point numbers) and normalize between 0 and 1\n",
        "x_train_fl = x_train_v.astype('float32') / 255.\n",
        "x_test_fl = x_test_v.astype('float32') / 255.\n",
        "print(x_train_fl.shape, x_test_fl.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkseH2Pw9NpN",
        "outputId": "86921ddd-d7e3-4af4-a71a-5b8013e96533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(71, 2) (31, 2)\n"
          ]
        }
      ],
      "source": [
        " # Set a constant for the number of recognized classes to one hot encoding.\n",
        "CLASS_COUNT = 2  # crosses=1 and zeros=0\n",
        "# Convert responses to one_hot_encoding format\n",
        "y_train_enc = utils.to_categorical(y_train_base, CLASS_COUNT)\n",
        "y_test_enc = utils.to_categorical(y_test_base, CLASS_COUNT)\n",
        "print(y_train_enc.shape, y_test_enc.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a6h7Ab3HbR2"
      },
      "source": [
        "##Creation of a neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJLh3F3N2DCD",
        "outputId": "e2b1218a-66c6-48e7-96be-3e2c5a84a5b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16)                6416      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,570\n",
            "Trainable params: 6,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=400, activation='relu'))    \n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(CLASS_COUNT, activation='softmax')) \n",
        " \n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT-LSskJinlx"
      },
      "source": [
        "## Neural network training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtGOThG3ivEe",
        "outputId": "2a266082-5fec-4fd4-8d01-589c8811d01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.8451\n",
            "Epoch 2/25\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.8451\n",
            "Epoch 3/25\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.8592\n",
            "Epoch 4/25\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4457 - accuracy: 0.8592\n",
            "Epoch 5/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.9155\n",
            "Epoch 6/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8873\n",
            "Epoch 7/25\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4190 - accuracy: 0.8873\n",
            "Epoch 8/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8873\n",
            "Epoch 9/25\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3971 - accuracy: 0.9155\n",
            "Epoch 10/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.9296\n",
            "Epoch 11/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.9437\n",
            "Epoch 12/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.9437\n",
            "Epoch 13/25\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.9437\n",
            "Epoch 14/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.9577\n",
            "Epoch 15/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.9577\n",
            "Epoch 16/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.9577\n",
            "Epoch 17/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.9577\n",
            "Epoch 18/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.9718\n",
            "Epoch 19/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.9718\n",
            "Epoch 20/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2981 - accuracy: 0.9718\n",
            "Epoch 21/25\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.9718\n",
            "Epoch 22/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2820 - accuracy: 0.9859\n",
            "Epoch 23/25\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.9859\n",
            "Epoch 24/25\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.9859\n",
            "Epoch 25/25\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x15f2932d400>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train_fl,        # training sample, input data\n",
        "          y_train_enc,       # training set, output\n",
        "          batch_size=128, # number of examples that the neuron processes before one weight change\n",
        "          epochs=25,      # the number of epochs when the neuron is trained on all examples of the sample\n",
        "          verbose=1          )      # 0 - do not visualize learning progress, 1 - visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "mShryDXpmrwt"
      },
      "outputs": [],
      "source": [
        "#save the weights of your model\n",
        "model.save_weights('model.h5')\n",
        "model.load_weights('model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn56wWa2myH4"
      },
      "source": [
        "## Handwriting recognition X, 0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z898MRJutKPv",
        "outputId": "271674f3-f641-42bf-eb42-c7dd4a014e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(71, 20, 20) (31, 20, 20)\n"
          ]
        }
      ],
      "source": [
        "x_train_base=np.reshape(x_train_base,(x_train_base.shape[0],x_train_base.shape[1],-1))\n",
        "x_test_base=np.reshape(x_test_base,(x_test_base.shape[0],x_test_base.shape[1],-1))\n",
        "print(x_train_base.shape,x_test_base.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "hEam9wvQm-e9",
        "outputId": "f7263862-59e6-4b0b-d04d-dfe39e5801ea"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "#   test to recognize\n",
        "n_rec = np.random.randint(x_test_base.shape[0])\n",
        "\n",
        "# Displaying a picture from the test set under the number n_rec\n",
        "plt.imshow(x_test_base[n_rec], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrEZpIDGuIzh",
        "outputId": "205a4296-35ac-4775-dbe6-44701b2d1a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(400,)\n"
          ]
        }
      ],
      "source": [
        "#Selecting the desired image from the test sample\n",
        "x = x_test_fl[n_rec]\n",
        "\n",
        "# Data Form Validation\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CrAFqH8vFqD",
        "outputId": "0ac7f695-3472-40a9-b0e9-6821d50a768d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 400)\n"
          ]
        }
      ],
      "source": [
        "# Adding one axis at the beginning so that the neuron can recognize the example\n",
        "# An array of one example, since the neuron accepts exactly arrays of examples (batches) for recognition\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "# Data form validation\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "mgSmpE_yvPUH"
      },
      "outputs": [],
      "source": [
        "  #Example recognition\n",
        "  # crosses=1 and zeros=0\n",
        "prediction = model.predict(x) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmBC60cOvTrd",
        "outputId": "9ec30066-ad96-4480-c5a3-6c146c9d8a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.66543657 0.33456337]]\n"
          ]
        }
      ],
      "source": [
        "# The output of the result is a vector of 2 numbers\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa4n5is0w_-F",
        "outputId": "8f4d0b74-a437-4ef1-cf1f-c921f3307bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recognized : 0\n"
          ]
        }
      ],
      "source": [
        "# Get and print the index of the largest element (this is the value of the digit that the network recognized)\n",
        "pred = np.argmax(prediction)\n",
        "print(f'Recognized : {pred}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "1ec8c1a056610f9e2b425ecee72ab231842da7af27317589820e05cd48a3390e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
